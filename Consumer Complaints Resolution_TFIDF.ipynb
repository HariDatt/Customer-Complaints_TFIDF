{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b41dd5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from string import punctuation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d74398ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and testing data are merged into single CSV and named \"Whole.csv\" for data cleaning purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48ce932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile1=r'C:\\Users\\dattmish\\Documents\\IITK\\Project 1\\Trial_2/Whole.csv'\n",
    "Complete=pd.read_csv(datafile1).drop(['Issue','Consumer complaint narrative'],1)\n",
    "Issue=(pd.read_csv(datafile1)['Issue'])\n",
    "narrative=(pd.read_csv(datafile1)['Consumer complaint narrative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39e3f4c",
   "metadata": {},
   "source": [
    "# Issue and Complaint Narrative Columns were dropped to perform other operatoions and rest of the operations are kept same as in benchmark script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b99df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Date received','Date sent to company']:\n",
    "    Complete[col]=pd.to_datetime(Complete[col],infer_datetime_format=True)\n",
    "Complete['day_diff']=pd.to_numeric(Complete['Date sent to company']-Complete['Date received'])\n",
    "\n",
    "for col in ['Date received','Date sent to company']:\n",
    "    Complete.drop([col],1,inplace=True)\n",
    "    \n",
    "for col in ['Sub-product','Sub-issue','Company public response','Tags','Consumer consent provided?']:\n",
    "    varname=col.replace('-','_').replace('?','').replace(\" \",'_')+'_isNan'\n",
    "    Complete[varname]=np.where(pd.isnull(Complete[col]),1,0)\n",
    "    Complete.drop([col],1,inplace=True)\n",
    "\n",
    "for col in ['ZIP code','Company']:\n",
    "    Complete.drop([col],1,inplace=True)\n",
    "\n",
    "k=Complete['State'].value_counts()\n",
    "for val in k.axes[0][0:15]:\n",
    "    varname='State_'+val.replace(',','_').replace(' ','_')\n",
    "    Complete[varname]=np.where(Complete['State']==val,1,0)\n",
    "del Complete['State']\n",
    "\n",
    "for col in ['Product','Submitted via','Company response to consumer','Timely response?']:    \n",
    "    temp=pd.get_dummies(Complete[col],prefix=col,drop_first=True)\n",
    "    Complete=pd.concat([temp,Complete],1)\n",
    "    Complete.drop([col],1,inplace=True)\n",
    "\n",
    "Complete['Consumer disputed?']=np.where(Complete['Consumer disputed?']==\"Yes\",1,0)\n",
    "# Complete.dtypes\n",
    "# Complete.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415c7ce5",
   "metadata": {},
   "source": [
    "# TFIDF for Issue & Narrative Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f9ae6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_stopwords = set(stopwords.words('english')+list(punctuation))\n",
    "\n",
    "# lem = WordNetLemmatizer()\n",
    "# stem = PorterStemmer()\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0da7f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "Issue=Issue.str.lower()\n",
    "Issue = Issue.apply(lambda x: ' '.join([word for word in x.split() if word not in (eng_stopwords)]))\n",
    "Issue = Issue.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d056b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "narrative=narrative.str.lower()\n",
    "narrative=narrative.fillna(\"\")\n",
    "narrative = narrative.apply(lambda x: ' '.join([word for word in x.split() if word not in (eng_stopwords)]))\n",
    "narrative = narrative.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fc4117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=300,analyzer='word', tokenizer=dummy_fun, preprocessor=dummy_fun,token_pattern=None, use_idf=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12fea3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Narrative_vect=tfidf.fit_transform(narrative)\n",
    "Issue_vect=tfidf.fit_transform(Issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccd63459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making single dataframe for all the processed data\n",
    "Final=pd.concat([pd.DataFrame(Issue_vect.toarray()), pd.DataFrame(Narrative_vect.toarray()),Complete], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01c8ac7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(598027, 300)\n",
      "(598027, 167)\n",
      "(598027, 46)\n",
      "(598027, 513)\n"
     ]
    }
   ],
   "source": [
    "print(Narrative_vect.shape)\n",
    "print(Issue_vect.shape)\n",
    "print(Complete.shape)\n",
    "print(Final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e67b72",
   "metadata": {},
   "source": [
    "# bifurcating the processed data into original data and fitting the model \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "166e7c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperating original training and testing sets into cd_train and CD_test\n",
    "cd_test=Final.iloc[478421:,:]\n",
    "cd_test=cd_test.drop(['Consumer disputed?'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00e396d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(478421, 513)\n",
      "(119606, 512)\n"
     ]
    }
   ],
   "source": [
    "cd_train=Final.iloc[:478421,:]\n",
    "x=cd_train.drop(['Consumer disputed?','Complaint ID'],1)\n",
    "y=cd_train['Consumer disputed?']\n",
    "print(cd_train.shape)\n",
    "print(cd_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "342855cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86538ec",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "465fcbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# fit the model to the training set\n",
    "\n",
    "rf_clf.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the test set results\n",
    "\n",
    "y_pred = rf_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fd5a75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with 100 decision-trees : 0.7704\n",
      "ROC AUC Score is : 0.511019\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy score \n",
    "\n",
    "auc_score1 = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print('Model accuracy score with 100 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n",
    "print('ROC AUC Score is : {0:0.6f}'.format(auc_score1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2115ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction=np.where(rf_clf.predict(cd_test.drop(['Complaint ID'],1))==1,\"Yes\",\"No\")\n",
    "# submission=pd.DataFrame(list(zip(cd_test['Complaint ID'],list(prediction))),\n",
    "#                        columns=['Complaint ID','Consumer disputed?'])\n",
    "# submission.to_csv(' Submission 2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aad8df3",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b0b2707",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5469498e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc9dece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_LogisticR = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0418119e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with 100 decision-trees : 0.7902\n",
      "ROC AUC Score is : 0.500000\n"
     ]
    }
   ],
   "source": [
    "auc_score2 = roc_auc_score(y_test, y_pred_LogisticR)\n",
    "\n",
    "print('Model accuracy score with 100 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred_LogisticR)))\n",
    "print('ROC AUC Score is : {0:0.6f}'.format(auc_score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be0147e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction=np.where(clf.predict(cd_test.drop(['Complaint ID'],1))==1,\"Yes\",\"No\")\n",
    "# submission=pd.DataFrame(list(zip(cd_test['Complaint ID'],list(prediction))),\n",
    "#                        columns=['Complaint ID','Consumer disputed?'])\n",
    "# submission.to_csv(' Submission 3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb85c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
